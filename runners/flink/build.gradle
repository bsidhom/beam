/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * License); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an AS IS BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

apply from: project(":").file("build_rules.gradle")
applyJavaNature()

description = "Apache Beam :: Runners :: Flink"

/*
 * We need to rely on manually specifying these evaluationDependsOn to ensure that
 * the following projects are evaluated before we evaluate this project. This is because
 * we are attempting to reference the "sourceSets.test.output" directly.
 * TODO: Swap to generating test artifacts which we can then rely on instead of
 * the test outputs directly.
 */
evaluationDependsOn(":model:fn-execution")
evaluationDependsOn(":runners:core-java")
evaluationDependsOn(":sdks:java:core")

test {
  systemProperty "log4j.configuration", "log4j-test.properties"
  jvmArgs "-XX:-UseGCOverheadLimit"
  if (System.getProperty("beamSurefireArgline")) {
    jvmArgs System.getProperty("beamSurefireArgline")
  }
}

configurations {
  validatesRunnerBatch
}

def flink_version = "1.4.0"

dependencies {
  compile library.java.guava
  shadow project(path: ":sdks:java:core", configuration: "shadow")
  shadow project(path: ":runners:core-java", configuration: "shadow")
  shadow project(path: ":runners:core-construction-java", configuration: "shadow")
  shadow library.java.jackson_annotations
  shadow library.java.findbugs_jsr305
  shadow library.java.slf4j_api
  shadow library.java.joda_time
  shadow library.java.commons_compress
  shadow "org.apache.flink:flink-clients_2.11:$flink_version"
  shadow "org.apache.flink:flink-core:$flink_version"
  shadow "org.apache.flink:flink-metrics-core:$flink_version"
  shadow "org.apache.flink:flink-java:$flink_version"
  shadow "org.apache.flink:flink-runtime_2.11:$flink_version"
  shadow "org.apache.flink:flink-streaming-java_2.11:$flink_version"
  shadowTest project(path: ":sdks:java:core", configuration: "shadowTest")
  shadowTest project(":model:fn-execution").sourceSets.test.output
  shadowTest project(":runners:core-java").sourceSets.test.output
  shadowTest library.java.commons_lang3
  shadowTest library.java.hamcrest_core
  shadowTest library.java.junit
  shadowTest library.java.mockito_core
  shadowTest library.java.google_api_services_bigquery
  shadowTest library.java.jackson_dataformat_yaml
  shadowTest "org.apache.flink:flink-core:$flink_version:tests"
  shadowTest "org.apache.flink:flink-runtime_2.11:$flink_version:tests"
  shadowTest "org.apache.flink:flink-streaming-java_2.11:$flink_version:tests"
  shadowTest "org.apache.flink:flink-test-utils_2.11:$flink_version"
  validatesRunnerBatch project(path: ":beam-sdks-parent:beam-sdks-java-parent:beam-sdks-java-core", configuration: "shadowTest")
  validatesRunnerBatch project(path: project.path, configuration: "shadow")
}

def outputDirectory = "$buildDir/validatesRunner/"

task validatesRunnerCopy(type: Copy) {
  println "UNZIPPING:"
  from zipTree({
    findProject(":beam-sdks-parent:beam-sdks-java-parent:beam-sdks-java-core").getConfigurations().shadowTest.getArtifacts().getFiles().getSingleFile()
  })
  into outputDirectory
}

task validatesRunnerBatch(type: Test) {
  dependsOn validatesRunnerCopy
  println "ZIP OUTPUT: " + outputDirectory
  systemProperty "beamTestPipelineOptions", '["--runner=TestFlinkRunner", "--streaming=false"]'
  classpath = configurations.validatesRunnerBatch
  //testClassesDirs = findProject(":beam-sdks-parent:beam-sdks-java-parent:beam-sdks-java-core").sourceSets.test.output
  testClassesDirs = files(outputDirectory)
  println "TEST DIR: " + getTestClassesDirs().getFiles()
  maxParallelForks 24
  useJUnit {
    includeCategories "org.apache.beam.sdk.testing.ValidatesRunner"
    excludeCategories "org.apache.beam.sdk.testing.FlattenWithHeterogeneousCoders"
    excludeCategories "org.apache.beam.sdk.testing.LargeKeys\$Above100MB"
    excludeCategories "org.apache.beam.sdk.testing.UsesSplittableParDo"
    excludeCategories "org.apache.beam.sdk.testing.UsesCommittedMetrics"
    excludeCategories "org.apache.beam.sdk.testing.UsesTestStream"
  }
}

task packageTests(type: Jar) {
  from sourceSets.test.output
  classifier = "tests"
}

artifacts.archives packageTests
